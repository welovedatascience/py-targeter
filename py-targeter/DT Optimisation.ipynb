{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Aug 17 10:44:34 AM: Encountered unexpected exception importing solver GLOP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.6.2534). Expected < 9.5.0.Please open a feature request on cvxpy to enable support for this version.')\n",
      "(CVXPY) Aug 17 10:44:34 AM: Encountered unexpected exception importing solver PDLP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.6.2534). Expected < 9.5.0.Please open a feature request on cvxpy to enable support for this version.')\n"
     ]
    }
   ],
   "source": [
    "#import optbinning\n",
    "import pandas as pd\n",
    "from optbinning import BinningProcess\n",
    "import inspect\n",
    "import numpy as np\n",
    "from tempfile import mkdtemp\n",
    "import os\n",
    "import shutil\n",
    "from pickle import dump\n",
    "import subprocess\n",
    "from matplotlib import pyplot\n",
    "from adjustText import adjust_text\n",
    "import papermill\n",
    "import targeter\n",
    "from IPython.display import display, HTML\n",
    "from itables import init_notebook_mode, show\n",
    "import os\n",
    "import papermill\n",
    "from sklearn import decomposition, datasets\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import graphviz\n",
    "import pydotplus\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import d2_pinball_score\n",
    "from sklearn.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_3828\\2303263537.py:4: DtypeWarning: Columns (256) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(r\"C:\\Users\\natha\\OneDrive\\Documents\\WeLoveDataScience\\df-wlds-equete2014.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from targeter import Targeter\n",
    "#dtypes = {col: 'float32' for col in df2.columns if df2[col].dtype == 'float64', str: 'str'}\n",
    "df2 = pd.read_csv(r\"C:\\Users\\natha\\OneDrive\\Documents\\WeLoveDataScience\\df-wlds-equete2014.csv\")\n",
    "target = 'O_523'\n",
    "variable = 'AGE'\n",
    "df2 = df2[df2[target].notnull()]\n",
    "import pandas as pd \n",
    "df3 = pd.read_csv(\"C:/Users/natha/OneDrive/Documents/WeLoveDataScience/adult.csv\")\n",
    "dtypes = {col1: 'float32' for col1 in df2.columns if df2[col1].dtype == 'float64'}\n",
    "dtypes.update({col2: 'int32' for col2 in df2.columns if df2[col2].dtype == 'int64'})\n",
    "dtypes.update({col3 : 'object' for col3 in df2.columns if df2[col3].dtype == 'object'})\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\natha\\OneDrive\\Documents\\WeLoveDataScience\\df-wlds-equete2014.csv\", dtype = dtypes)\n",
    "target = 'O_523'\n",
    "variable = 'AGE'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[target].notnull()]\n",
    "df = df.drop(df[df['R_Client_Taux_de_plainte'] == np.inf].index)\n",
    "df = df.drop(df[df['R_Client_pct_enquete_repondu'] == np.inf].index)\n",
    "meta = pd.read_excel(r\"C:\\Users\\natha\\OneDrive\\Documents\\WeLoveDataScience\\meta data.xlsx\", sheet_name=\"Feuil1\")\n",
    "meta2 = pd.read_excel(r\"C:\\Users\\natha\\OneDrive\\Documents\\meta data_new.xlsx\", sheet_name=\"Feuil1\")\n",
    "\n",
    "#df[\"Centre_tri\"] = df['T_CodePostal'].apply(attribuer_ville)\n",
    "#df[\"Province\"]=df['T_CodePostal'].apply(attribuer_province)\n",
    "\n",
    "def target_to_class(target):\n",
    "    if target < 4:\n",
    "        return \"[0 ; 4[\"\n",
    "    elif target >=4 and target <8:\n",
    "        return \"[4 ; 8[\"\n",
    "    elif target >=8 and target <9:\n",
    "        return \"[8 ; 9[\"\n",
    "    elif target >= 9:\n",
    "        return \"[9 ; 10]\"\n",
    "\n",
    "df['O_523_to_class'] = df['O_523'].apply(target_to_class)\n",
    "\n",
    "#Target O_523\n",
    "#tar = Targeter(target=target,data=df,categorical_variables=list(df.select_dtypes(include=[\"object\"]).columns), exclude_vars= ['N_ConfortGap','N_Confort','N_Cote_actuelle','O_415','O_679','O_414','O_362','O_524','O_363','O_374', 'B_521', 'N_Cote_Actuelle','O_674','O_365','O 370','O_366','O_373', 'O_372','O_367', 'O_369'])\n",
    "#target O_524-\n",
    "\n",
    "#df['Langue_Identique'] = ((df['C_LangueClient'] == 'De') & (df['B_Gerant_Langue_Allemand'] == 1)) | \\\n",
    "                         #((df['C_LangueClient'] == 'En') & (df['B_Gerant_Langue_Anglais'] == 1)) | \\\n",
    "                         #((df['C_LangueClient'] == 'Fr') & (df['B_Gerant_Langue_Francais'] == 1)) | \\\n",
    "                         #((df['C_LangueClient'] == 'Nl') & (df['B_Gerant_Langue_Neerlandais'] == 1))\n",
    "\n",
    "df = df[df[\"O_524\"].notnull()]\n",
    "df = df[df[\"N_SATISFACTION_CLIENT_CUR\"].notnull()]\n",
    "df = df[df['O_523'].notnull()]\n",
    "\n",
    "#tar = Targeter(target='O_523',data=df,categorical_variables=list(df.select_dtypes(include=[\"object\"]).columns),var_col=\"Nom colonne\", label_col=\"Description\",metadata=meta, exclude_vars= list(set(['C_CommunauteClient','B_521','D_debutsejour_month','D_DateInsertion_year','Centre_tri','D_DateReservation_month','D_DateInsertion_month','N_Confort','B_Gerant_Langue_Allemand','B_Gerant_Langue_Anglais','B_Gerant_Langue_Francais','B_Gerant_Langue_Neerlandais','O_523_to_class','I_IDLocation','Unnamed: 0','I_IDReservation','GeoPosX','N_Delais_Enquete','R_Maison_pct_enquete_repondu', 'N_Maison_Nombre_plainteClient', 'N_Maison_Enquete_repondu','N_Maison_Nombre_sejour','N_AgeMin', 'N_BookingWindow', 'D_debutsejour_year', 'D_DateReservation_year'] + list(meta[meta[\"Exclude \"]==\"x\"][\"Nom colonne\"].values))))\n",
    "#tar = Targeter(target=target,data=df,categorical_variables=list(df.select_dtypes(include=[\"object\"]).columns),var_col=\"Nom colonne\", label_col=\"newname\",metadata=meta, exclude_vars= ['O_374','N_Cote_actuelle','O_366','O_373','N_Confort','O_368','O_414','O_363','O_679','O_362','O_523','O_415','O_371','N_Cote_Actuelle','O_370','O_372','N_ConfortGap','O_367','O_524','O_365','O_369','B_532','B_521','B_HC_25','O_388','B_403','N_HC_53','O_393'])\n",
    "tar = Targeter(target='O_523',data=df,categorical_variables=list(df.select_dtypes(include=[\"object\"]).columns),var_col=\"Nom colonne\", label_col=\"Description\",metadata=meta, exclude_vars= list(set(['D_debutsejour_month','D_DateInsertion_year','Centre_tri','D_DateReservation_month','D_DateInsertion_month','B_Gerant_Langue_Allemand','B_Gerant_Langue_Anglais','B_Gerant_Langue_Francais','B_Gerant_Langue_Neerlandais','O_523_to_class','I_IDLocation','Unnamed: 0','I_IDReservation','GeoPosX', 'D_debutsejour_year', 'D_DateReservation_year'] + list(meta[meta[\"Exclude \"]==\"x\"][\"Nom colonne\"].values))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "def backward_stepwise_selection_ridge(X, y, alpha=0.23357214690901212):\n",
    "    included_features = list(X.columns)\n",
    "    while len(included_features) > 0:\n",
    "        model = Ridge(alpha=alpha,random_state=seed)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X[included_features], y, test_size=0.2, random_state=seed)\n",
    "        model.fit(X_train, y_train)\n",
    "        coef = model.coef_\n",
    "        zero_coef_indices = np.where(coef == 0)[0]\n",
    "        if len(zero_coef_indices) > 0:\n",
    "            # Find the feature with zero coefficient and remove it\n",
    "            feature_to_remove = included_features[zero_coef_indices[0]]\n",
    "            included_features.remove(feature_to_remove)\n",
    "        else:\n",
    "            break\n",
    "    return included_features\n",
    "\n",
    "selected_features = backward_stepwise_selection_ridge(one_hot_df, Y)\n",
    "print(\"Selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_stepwise_selection_ridge(X, y, alpha=0.3274549162877732):\n",
    "    included_features = []\n",
    "    remaining_features = list(X.columns)\n",
    "    while len(remaining_features) > 0:\n",
    "        best_score = float('-inf')\n",
    "        best_feature = None\n",
    "        for feature in remaining_features:\n",
    "            model = RidgeCV(alphas=[alpha], cv=5)\n",
    "            features_to_include = included_features + [feature]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X[features_to_include], y, test_size=0.2, random_state=seed)\n",
    "            model.fit(X_train, y_train)\n",
    "            score = model.score(X_test, y_test)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_feature = feature\n",
    "        if best_feature is not None:\n",
    "            included_features.append(best_feature)\n",
    "            remaining_features.remove(best_feature)\n",
    "        else:\n",
    "            break\n",
    "    return included_features\n",
    "\n",
    "selected_features = forward_stepwise_selection_ridge(one_hot_df, Y)\n",
    "print(\"Selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def trouver_variables_correlees(dataframe, seuil_correlation):\n",
    "    colonnes_numeriques = dataframe.select_dtypes(include=[int, float]).columns \n",
    "    dataframe_numerique = dataframe[colonnes_numeriques] \n",
    "    matrice_correlation = dataframe_numerique.corr()  \n",
    "    variables_correlees = []   \n",
    "    for i in range(len(matrice_correlation.columns)):\n",
    "        for j in range(i+1, len(matrice_correlation.columns)):\n",
    "            if abs(matrice_correlation.iloc[i, j]) > seuil_correlation:\n",
    "                variables_correlees.append((matrice_correlation.columns[i], matrice_correlation.columns[j]))   \n",
    "    return variables_correlees\n",
    "\n",
    "seuil_correlation = 0.5 \n",
    "variables_correlees = trouver_variables_correlees(one_hot_df[fws_c], seuil_correlation)\n",
    "print(\"Variables corrélées : \", variables_correlees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_count_min=500\n",
    "filter_n=30\n",
    "self = tar\n",
    "a1 = self.filter(n=filter_n, metric=\"quality_score\").selection\n",
    "if self.target_type == \"continuous\":\n",
    "        a2 = self.filter(n=filter_n, metric=\"Max Mean\", count_min=filter_count_min).selection\n",
    "        self.selection = list(set(a1 + a2))\n",
    "\n",
    "len(self.selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m one_hot_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mget_dummies(df[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselection],drop_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m one_hot_df \u001b[39m=\u001b[39m one_hot_df\u001b[39m.\u001b[39mfillna(one_hot_df\u001b[39m.\u001b[39mmean())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "one_hot_df = pd.get_dummies(df[self.selection],drop_first=True)\n",
    "one_hot_df = one_hot_df.fillna(one_hot_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bws = ['N_NbrAdo', 'N_Maison_Cote_Maison_Moyenne_18M', 'M_Charges_Agence', 'N_Maison_Nombre_plainte', 'M_Caution', 'N_NbrBebe', 'M_TotalAssurance', 'N_HC_22', 'M_TotalSejourAdultesNuit', 'N_Lit1p', 'N_SuperficieParCapacite', 'N_Lit2p', 'N_nombre_nuit', 'N_Chambres', 'N_HC_21', 'M_TotalSejourPers', 'R_Maison_Taux_de_plainteClient', 'R_Maison_Taux_de_plainte', 'N_SuperficieParAdulteAdoEnfant', 'M_TotalSejourPersNuit', 'N_NbrEnfants', 'N_HC_53', 'M_Charges_SurPlace', 'Superficie', 'N_HC_48', 'N_Maison_Cote_Maison_Moyenne', 'N_NbrAnimaux', 'C_PaysClient_Angleterre', 'C_PaysClient_Belgique', 'C_PaysClient_France', 'C_PaysClient_Pays-Bas', 'C_PaysClient_autre', 'B_Filtre_Equipement_JeuxInterieurs_1', 'B_Filtre_TypeBien_Maison_1', 'B_HC_45_1', 'B_HC_41_1', 'B_HC_25_1', 'B_Maison_Online_1', 'B_Filtre_Equipement_FeuOuvert_1', 'B_Filtre_TypeBien_Villa_1', 'B_Filtre_TypeBien_Seminaire_1', 'C_GroupeSelonCompo_Groupe Multi-généartion', 'C_GroupeSelonCompo_Jeune Groupe Multi-familliaux', 'C_GroupeSelonCompo_Jeunes Parents', 'C_GroupeSelonCompo_Jeunes_amis', 'C_GroupeSelonCompo_Vieux Groupe Multi-familliaux', 'C_GroupeSelonCompo_Vieux Parents', 'C_GroupeSelonCompo_Vieux_amis', 'C_GroupeSelonCompo_bizard', 'B_HC_13_1', 'B_HC_6_1', 'B_HC_18_1', 'B_HC_10_1', 'B_MAISON_WELLNESS_1', 'B_HC_3_1', 'B_HC_30_1', 'C_LangueClient_En', 'C_LangueClient_Fr', 'C_LangueClient_Nl', 'B_HC_27_1', 'B_HC_12_1', 'B_HC_44_1', 'B_HC_8_1', 'B_Passage_statut_3_1']\n",
    "fws = ['N_Maison_Cote_Maison_Moyenne_18M', 'C_LangueClient_Nl', 'N_nombre_nuit', 'N_Chambres', 'B_Filtre_Equipement_FeuOuvert_1', 'M_TotalSejourAdultesNuit', 'B_Filtre_TypeBien_Villa_1', 'B_HC_27_1', 'N_NbrBebe', 'B_Maison_Online_1', 'C_GroupeSelonCompo_Jeunes_amis', 'C_PaysClient_Angleterre', 'C_LangueClient_En', 'C_LangueClient_Fr', 'C_GroupeSelonCompo_Vieux Groupe Multi-familliaux', 'N_SuperficieParCapacite', 'N_Maison_Cote_Maison_Moyenne', 'N_Lit2p', 'M_Charges_SurPlace', 'M_Charges_Agence', 'N_NbrAnimaux', 'B_HC_6_1', 'B_Filtre_TypeBien_Maison_1', 'B_HC_10_1', 'B_HC_3_1', 'N_HC_53', 'B_MAISON_WELLNESS_1', 'B_HC_18_1', 'B_Filtre_Equipement_JeuxInterieurs_1', 'N_Lit1p', 'C_GroupeSelonCompo_Vieux_amis', 'C_GroupeSelonCompo_Vieux Parents', 'C_GroupeSelonCompo_Jeunes Parents', 'C_PaysClient_Pays-Bas', 'C_PaysClient_Belgique', 'B_HC_8_1', 'N_Maison_Nombre_plainte', 'N_HC_48', 'M_TotalSejourPers', 'N_SuperficieParAdulteAdoEnfant', 'B_Filtre_TypeBien_Seminaire_1', 'M_TotalSejourPersNuit', 'N_NbrEnfants', 'B_Passage_statut_3_1', 'Superficie', 'N_HC_22', 'C_PaysClient_France', 'B_HC_30_1', 'B_HC_44_1', 'B_HC_13_1', 'R_Maison_Taux_de_plainte', 'R_Maison_Taux_de_plainteClient', 'M_Caution', 'B_HC_25_1', 'C_GroupeSelonCompo_bizard', 'M_TotalAssurance', 'B_HC_45_1', 'B_HC_41_1', 'C_GroupeSelonCompo_Jeune Groupe Multi-familliaux', 'C_GroupeSelonCompo_Groupe Multi-généartion', 'C_PaysClient_autre', 'B_HC_12_1', 'N_NbrAdo', 'N_HC_21']\n",
    "fws_c = ['C_LangueClient_Nl', 'N_nombre_nuit', 'B_Filtre_Equipement_FeuOuvert_1', 'M_TotalSejourAdultesNuit', 'B_Filtre_TypeBien_Villa_1', 'B_HC_27_1', 'N_NbrBebe', 'B_Maison_Online_1', 'C_GroupeSelonCompo_Jeunes_amis', 'C_PaysClient_Angleterre', 'C_LangueClient_En', 'C_LangueClient_Fr', 'C_GroupeSelonCompo_Vieux Groupe Multi-familliaux', 'N_SuperficieParCapacite', 'N_Maison_Cote_Maison_Moyenne', 'N_Lit2p', 'M_Charges_SurPlace', 'M_Charges_Agence', 'N_NbrAnimaux', 'B_HC_6_1', 'B_Filtre_TypeBien_Maison_1', 'B_HC_10_1', 'B_HC_3_1', 'N_HC_53', 'B_MAISON_WELLNESS_1', 'B_HC_18_1', 'B_Filtre_Equipement_JeuxInterieurs_1', 'N_Lit1p', 'C_GroupeSelonCompo_Vieux_amis', 'C_GroupeSelonCompo_Vieux Parents', 'C_GroupeSelonCompo_Jeunes Parents', 'C_PaysClient_Pays-Bas', 'C_PaysClient_Belgique', 'B_HC_8_1', 'N_Maison_Nombre_plainte', 'N_HC_48', 'M_TotalSejourPers', 'N_SuperficieParAdulteAdoEnfant', 'B_Filtre_TypeBien_Seminaire_1', 'N_NbrEnfants', 'B_Passage_statut_3_1', 'N_HC_22', 'C_PaysClient_France', 'B_HC_30_1', 'B_HC_44_1', 'B_HC_13_1', 'R_Maison_Taux_de_plainte', 'R_Maison_Taux_de_plainteClient', 'M_Caution', 'B_HC_25_1', 'C_GroupeSelonCompo_bizard', 'M_TotalAssurance', 'B_HC_45_1', 'B_HC_41_1', 'C_GroupeSelonCompo_Jeune Groupe Multi-familliaux', 'C_GroupeSelonCompo_Groupe Multi-généartion', 'C_PaysClient_autre', 'B_HC_12_1', 'N_NbrAdo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_hot_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_interactions \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(one_hot_df[new_selection])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'one_hot_df' is not defined"
     ]
    }
   ],
   "source": [
    "df_interactions = pd.DataFrame(one_hot_df[new_selection])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = one_hot_df.columns\n",
    "for i in range (0,len(variables) - 1):\n",
    "    df_interactions[variables[i]+'^2'] = one_hot_df[variables[i]]**2\n",
    "    for j in range(i+1,len(variables) - 1):\n",
    "        df_interactions[variables[i] + '*' +  variables[j]] = one_hot_df[variables[i]]*one_hot_df[variables[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA(random_state=seed)\n",
    "dtreeReg = tree.DecisionTreeRegressor(min_samples_leaf=700,min_samples_split=2000,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df_sc = StandardScaler().fit_transform(one_hot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[df[target].notnull()]['O_523'].values\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(one_hot_df,Y, test_size=0.2, shuffle=True,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "turned_parameters = [{\"max_depth\" : [4,5,6,7,8,9,10,11,12]}, {\"max_features\" : [i for i in range(30,50)]}]\n",
    "\n",
    "grid_search = GridSearchCV(tree.DecisionTreeRegressor(min_samples_leaf=700,min_samples_split=2000,random_state=seed,criterion=\"friedman_mse\"), turned_parameters)\n",
    "\n",
    "grid_search = grid_search.fit(X0_train,Y0_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = list(range(1,one_hot_df.shape[1]+1,1))\n",
    "criterion = [\"friedman_mse\"]\n",
    "max_depth = [4,5,6]\n",
    "parameters = dict(pca__n_components=n_components,dtreeReg__criterion=criterion,dtreeReg__max_depth=max_depth)\n",
    "clf = GridSearchCV(pipe, parameters,)\n",
    "clf.fit(X1_train, Y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Number Of Components:\", clf.best_estimator_.get_params()[\"pca__n_components\"])\n",
    "print(); print(clf.best_estimator_.get_params()[\"dtreeReg\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf1 = RandomForestRegressor(random_state=seed,min_samples_leaf=700,min_samples_split=2000)\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "pipe_rf1 = Pipeline(steps=[(\"std_slc\", std_slc),(\"pca\", pca),(\"rf1\", rf1)])\n",
    "parameters_rf1 = dict(pca__n_components=n_components,rf1__max_depth=max_depth,rf1__criterion=criterion,rf1__n_estimators=n_estimators)\n",
    "clf_rf = GridSearchCV(pipe, parameters_rf1)\n",
    "clf_rf.fit(X1_train,Y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_alpha_lasso(X, y, alphas=None, cv=5):\n",
    "    if alphas is None:\n",
    "        alphas = np.logspace(-6, 6, 13)  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    lasso_model = LassoCV(alphas=alphas, cv=cv)\n",
    "    lasso_model.fit(X_train, y_train)\n",
    "    best_alpha = lasso_model.alpha_\n",
    "    return best_alpha\n",
    "\n",
    "best_alpha = find_best_alpha_lasso(df_interactions, Y)\n",
    "print(\"Best alpha:\", best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X1_train)\n",
    "X_test_scaled = scaler.transform(X1_test)\n",
    "\n",
    "lasso_model = Lasso(alpha=0.0001)  \n",
    "\n",
    "selector = SequentialFeatureSelector(estimator=lasso_model, direction='forward', n_features_to_select=\"auto\")\n",
    "\n",
    "selector = selector.fit(X_train_scaled, Y1_train)\n",
    "\n",
    "selected_indices = selector.get_support()\n",
    "\n",
    "selected_feature_names = X1_train.columns[selected_indices]\n",
    "\n",
    "print(\"Caractéristiques sélectionnées :\", selected_feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[df[target].notnull()]['O_523'].values\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(one_hot_df[['Superficie', 'N_Lit2p', 'N_NbrAdo', 'N_Delais_Enquete','M_TotalSejourAdultesNuit', 'N_Maison_Enquete_repondu', 'N_nombre_nuit','N_SuperficieParAdulteAdoEnfant', 'M_Caution','N_Maison_Cote_Maison_Moyenne_18M', 'N_Maison_Nombre_plainteClient','N_Maison_Cote_Maison_Moyenne', 'N_HC_21', 'N_Maison_Nombre_sejour','N_NbrBebe', 'M_Charges_Agence', 'N_AgeMin','C_CommunauteClient_Angleterre_En', 'C_CommunauteClient_Belgique_De','C_CommunauteClient_Belgique_En', 'C_CommunauteClient_France_De','C_CommunauteClient_France_Nl', 'C_CommunauteClient_Pays-Bas_En','C_CommunauteClient_Pays-Bas_Fr', 'C_CommunauteClient_autre_En','C_CommunauteClient_autre_Fr', 'B_HC_12_1', 'B_HC_45_1','B_MAISON_WELLNESS_1', 'B_Filtre_Equipement_FeuOuvert_1', 'B_HC_10_1','B_HC_41_1', 'B_Filtre_TypeBien_Villa_1','C_GroupeSelonCompo_Groupe Multi-généartion','C_GroupeSelonCompo_Jeunes_amis', 'C_GroupeSelonCompo_Vieux Parents','C_GroupeSelonCompo_bizard', 'C_LangueClient_Fr', 'C_LangueClient_Nl','B_Maison_Online_1', 'B_Filtre_Equipement_JeuxInterieurs_1','B_HC_18_1']],Y, test_size=0.2, shuffle=True,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1 = tree.DecisionTreeRegressor(max_depth=6, min_samples_leaf=700, min_samples_split=2000,criterion=\"friedman_mse\",random_state=seed)\n",
    "dt1 = dt1.fit(X1_train,Y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dt1.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22786787646591222"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y1_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10342070334883213"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2_pinball_score(Y1_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_WOE = self.profiles.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[df[target].notnull()]['O_523'].values\n",
    "X0_train, X0_test, Y0_train, Y0_test = train_test_split(X_WOE,Y, test_size=0.2, shuffle=True,random_state=seed)\n",
    "X0_train_scaled = scaler.fit_transform(X0_train)\n",
    "X0_test_scaled = scaler.transform(X0_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt0 = tree.DecisionTreeRegressor(min_samples_leaf=700,min_samples_split=2000,random_state=seed,criterion=\"friedman_mse\",max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt0.fit(X0_train_scaled,Y0_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dt0.predict(X0_test_scaled)\n",
    "r2_score(Y0_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dt1.cost_complexity_pruning_path(X1_train,Y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(ccp_alphas[:-1], impurities[:-1], marker='o', drawstyle=\"steps-post\")\n",
    "ax.set_xlabel(\"effective alpha\")\n",
    "ax.set_ylabel(\"total impurity of leaves\")\n",
    "ax.set_title(\"Total Impurity vs Effective Alpha for training set\")\n",
    "\n",
    "optimal_ccp_alpha = ccp_alphas[np.argmin(impurities)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt1 = DecisionTreeClassifier()\n",
    "dt1.fit(X1_train, Y1_train)\n",
    "\n",
    "while True:\n",
    "    weakest_link = np.argmin(dt1.tree_.impurity)\n",
    "    if weakest_link == 0:\n",
    "        break\n",
    "    dt1.tree_.children_left[weakest_link] = dt1.tree_.children_right[weakest_link] = -1\n",
    "    \n",
    "    dt1.fit(X1_train, Y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dt1 = dt1.predict(X1_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1.score(X1_test,Y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "turned_parameters = [{\"n_estimators\" : [500,600,700,800,900,1000]}]\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestRegressor(min_samples_leaf=700,min_samples_split=2000,random_state=seed,criterion=\"friedman_mse\",max_depth=6), turned_parameters)\n",
    "\n",
    "grid_search = grid_search.fit(X1_train,Y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = RandomForestRegressor(max_depth=6, min_samples_leaf=700, min_samples_split=2000,criterion=\"friedman_mse\",random_state=seed,n_estimators=600)\n",
    "rf1 = rf1.fit(X1_train,Y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rf1 = rf1.predict(X1_test)\n",
    "r2_score(Y1_test,predictions_rf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pca = Pipeline([('pca', PCA(n_components=13, random_state=seed)),('tree',tree.DecisionTreeRegressor(max_depth=6, min_samples_leaf=700, min_samples_split=2000,criterion=\"squared_error\",random_state=seed))])\n",
    "forest_pca = Pipeline([('pca', PCA(n_components=13, random_state=seed)),('forest',RandomForestRegressor(max_depth=6, min_samples_leaf=700, min_samples_split=2000,criterion=\"squared_error\",random_state=seed))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pca.fit(X1_train,Y1_train)\n",
    "forest_pca.fit(X1_train,Y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_p = tree_pca.predict(X1_test)\n",
    "predictions_pf = forest_pca.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(Y1_test,predictions_pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gradient_boosting_model = GradientBoostingRegressor(n_estimators=500, random_state=seed)\n",
    "gradient_boosting_model.fit(X1_train, Y1_train)\n",
    "Y1_pred_gb = gradient_boosting_model.predict(X1_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(Y1_test,Y1_pred_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = Lasso(alpha=0.012742749857031322)\n",
    "lasso_model = lasso_model.fit(X0_train, Y0_train)\n",
    "selected_indices = np.where(lasso_model.coef_ != 0)[0]\n",
    "\n",
    "new_selection = X0_train.iloc[:, selected_indices]  \n",
    "#new_selection = X0_train[:, selected_indices] \n",
    "new_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_selection = new_selection.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
