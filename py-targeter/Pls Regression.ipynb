{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Aug 16 03:50:55 PM: Encountered unexpected exception importing solver GLOP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.6.2534). Expected < 9.5.0.Please open a feature request on cvxpy to enable support for this version.')\n",
      "(CVXPY) Aug 16 03:50:55 PM: Encountered unexpected exception importing solver PDLP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.6.2534). Expected < 9.5.0.Please open a feature request on cvxpy to enable support for this version.')\n"
     ]
    }
   ],
   "source": [
    "#import optbinning\n",
    "import pandas as pd\n",
    "from optbinning import BinningProcess\n",
    "import inspect\n",
    "import numpy as np\n",
    "from tempfile import mkdtemp\n",
    "import os\n",
    "import shutil\n",
    "from pickle import dump\n",
    "import subprocess\n",
    "from matplotlib import pyplot\n",
    "from adjustText import adjust_text\n",
    "import papermill\n",
    "import targeter\n",
    "from IPython.display import display, HTML\n",
    "from itables import init_notebook_mode, show\n",
    "import os\n",
    "import papermill\n",
    "from sklearn import decomposition, datasets\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import graphviz\n",
    "import pydotplus\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import d2_pinball_score\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_14916\\3565029356.py:4: DtypeWarning: Columns (256) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(r\"C:\\Users\\natha\\OneDrive\\Documents\\WeLoveDataScience\\df-wlds-equete2014.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from targeter import Targeter\n",
    "#dtypes = {col: 'float32' for col in df2.columns if df2[col].dtype == 'float64', str: 'str'}\n",
    "df2 = pd.read_csv(r\"C:\\Users\\natha\\OneDrive\\Documents\\WeLoveDataScience\\df-wlds-equete2014.csv\")\n",
    "target = 'O_523'\n",
    "variable = 'AGE'\n",
    "df2 = df2[df2[target].notnull()]\n",
    "import pandas as pd \n",
    "df3 = pd.read_csv(\"C:/Users/natha/OneDrive/Documents/WeLoveDataScience/adult.csv\")\n",
    "dtypes = {col1: 'float32' for col1 in df2.columns if df2[col1].dtype == 'float64'}\n",
    "dtypes.update({col2: 'int32' for col2 in df2.columns if df2[col2].dtype == 'int64'})\n",
    "dtypes.update({col3 : 'object' for col3 in df2.columns if df2[col3].dtype == 'object'})\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\natha\\OneDrive\\Documents\\WeLoveDataScience\\df-wlds-equete2014.csv\", dtype = dtypes)\n",
    "target = 'O_523'\n",
    "variable = 'AGE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some var from meta are not in the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natha\\OneDrive\\Documents\\WeLoveDataScience\\py-targeter\\.venv\\Lib\\site-packages\\optbinning\\binning\\continuous_binning.py:912: RuntimeWarning: invalid value encountered in cast\n",
      "  n_zeros = np.empty(n_bins).astype(np.int64)\n",
      "c:\\Users\\natha\\OneDrive\\Documents\\WeLoveDataScience\\py-targeter\\.venv\\Lib\\site-packages\\optbinning\\binning\\continuous_binning.py:912: RuntimeWarning: invalid value encountered in cast\n",
      "  n_zeros = np.empty(n_bins).astype(np.int64)\n"
     ]
    }
   ],
   "source": [
    "df = df[df[target].notnull()]\n",
    "df = df.drop(df[df['R_Client_Taux_de_plainte'] == np.inf].index)\n",
    "df = df.drop(df[df['R_Client_pct_enquete_repondu'] == np.inf].index)\n",
    "meta = pd.read_excel(r\"C:\\Users\\natha\\OneDrive\\Documents\\WeLoveDataScience\\meta data.xlsx\", sheet_name=\"Feuil1\")\n",
    "meta2 = pd.read_excel(r\"C:\\Users\\natha\\OneDrive\\Documents\\meta data_new.xlsx\", sheet_name=\"Feuil1\")\n",
    "\n",
    "#df[\"Centre_tri\"] = df['T_CodePostal'].apply(attribuer_ville)\n",
    "#df[\"Province\"]=df['T_CodePostal'].apply(attribuer_province)\n",
    "\n",
    "def target_to_class(target):\n",
    "    if target < 4:\n",
    "        return \"[0 ; 4[\"\n",
    "    elif target >=4 and target <8:\n",
    "        return \"[4 ; 8[\"\n",
    "    elif target >=8 and target <9:\n",
    "        return \"[8 ; 9[\"\n",
    "    elif target >= 9:\n",
    "        return \"[9 ; 10]\"\n",
    "\n",
    "df['O_523_to_class'] = df['O_523'].apply(target_to_class)\n",
    "\n",
    "#Target O_523\n",
    "#tar = Targeter(target=target,data=df,categorical_variables=list(df.select_dtypes(include=[\"object\"]).columns), exclude_vars= ['N_ConfortGap','N_Confort','N_Cote_actuelle','O_415','O_679','O_414','O_362','O_524','O_363','O_374', 'B_521', 'N_Cote_Actuelle','O_674','O_365','O 370','O_366','O_373', 'O_372','O_367', 'O_369'])\n",
    "#target O_524-\n",
    "\n",
    "#df['Langue_Identique'] = ((df['C_LangueClient'] == 'De') & (df['B_Gerant_Langue_Allemand'] == 1)) | \\\n",
    "                         #((df['C_LangueClient'] == 'En') & (df['B_Gerant_Langue_Anglais'] == 1)) | \\\n",
    "                         #((df['C_LangueClient'] == 'Fr') & (df['B_Gerant_Langue_Francais'] == 1)) | \\\n",
    "                         #((df['C_LangueClient'] == 'Nl') & (df['B_Gerant_Langue_Neerlandais'] == 1))\n",
    "\n",
    "df = df[df[\"O_524\"].notnull()]\n",
    "df = df[df[\"N_SATISFACTION_CLIENT_CUR\"].notnull()]\n",
    "df = df[df['O_523'].notnull()]\n",
    "\n",
    "#tar = Targeter(target='O_523',data=df,categorical_variables=list(df.select_dtypes(include=[\"object\"]).columns),var_col=\"Nom colonne\", label_col=\"Description\",metadata=meta, exclude_vars= list(set(['C_CommunauteClient','B_521','D_debutsejour_month','D_DateInsertion_year','Centre_tri','D_DateReservation_month','D_DateInsertion_month','N_Confort','B_Gerant_Langue_Allemand','B_Gerant_Langue_Anglais','B_Gerant_Langue_Francais','B_Gerant_Langue_Neerlandais','O_523_to_class','I_IDLocation','Unnamed: 0','I_IDReservation','GeoPosX','N_Delais_Enquete','R_Maison_pct_enquete_repondu', 'N_Maison_Nombre_plainteClient', 'N_Maison_Enquete_repondu','N_Maison_Nombre_sejour','N_AgeMin', 'N_BookingWindow', 'D_debutsejour_year', 'D_DateReservation_year'] + list(meta[meta[\"Exclude \"]==\"x\"][\"Nom colonne\"].values))))\n",
    "#tar = Targeter(target=target,data=df,categorical_variables=list(df.select_dtypes(include=[\"object\"]).columns),var_col=\"Nom colonne\", label_col=\"newname\",metadata=meta, exclude_vars= ['O_374','N_Cote_actuelle','O_366','O_373','N_Confort','O_368','O_414','O_363','O_679','O_362','O_523','O_415','O_371','N_Cote_Actuelle','O_370','O_372','N_ConfortGap','O_367','O_524','O_365','O_369','B_532','B_521','B_HC_25','O_388','B_403','N_HC_53','O_393'])\n",
    "tar = Targeter(target='O_523',data=df,categorical_variables=list(df.select_dtypes(include=[\"object\"]).columns),var_col=\"Nom colonne\", label_col=\"Description\",metadata=meta, exclude_vars= list(set(['D_debutsejour_month','D_DateInsertion_year','Centre_tri','D_DateReservation_month','D_DateInsertion_month','B_Gerant_Langue_Allemand','B_Gerant_Langue_Anglais','B_Gerant_Langue_Francais','B_Gerant_Langue_Neerlandais','O_523_to_class','I_IDLocation','Unnamed: 0','I_IDReservation','GeoPosX', 'D_debutsejour_year', 'D_DateReservation_year'] + list(meta[meta[\"Exclude \"]==\"x\"][\"Nom colonne\"].values))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_count_min=500\n",
    "filter_n=30\n",
    "self = tar\n",
    "a1 = self.filter(n=filter_n, metric=\"quality_score\").selection\n",
    "if self.target_type == \"continuous\":\n",
    "        a2 = self.filter(n=filter_n, metric=\"Max Mean\", count_min=filter_count_min).selection\n",
    "        self.selection = list(set(a1 + a2))\n",
    "\n",
    "len(self.selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 26.7 GiB for an array with shape (169452, 169452) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m one_hot_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mget_dummies(df,drop_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      2\u001b[0m one_hot_df \u001b[39m=\u001b[39m one_hot_df\u001b[39m.\u001b[39mfillna(one_hot_df\u001b[39m.\u001b[39mmean())\n",
      "File \u001b[1;32mc:\\Users\\natha\\OneDrive\\Documents\\WeLoveDataScience\\py-targeter\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:203\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    199\u001b[0m     with_dummies \u001b[39m=\u001b[39m [data\u001b[39m.\u001b[39mselect_dtypes(exclude\u001b[39m=\u001b[39mdtypes_to_encode)]\n\u001b[0;32m    201\u001b[0m \u001b[39mfor\u001b[39;00m col, pre, sep \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(data_to_encode\u001b[39m.\u001b[39mitems(), prefix, prefix_sep):\n\u001b[0;32m    202\u001b[0m     \u001b[39m# col is (column_name, column), use just column data here\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m     dummy \u001b[39m=\u001b[39m _get_dummies_1d(\n\u001b[0;32m    204\u001b[0m         col[\u001b[39m1\u001b[39;49m],\n\u001b[0;32m    205\u001b[0m         prefix\u001b[39m=\u001b[39;49mpre,\n\u001b[0;32m    206\u001b[0m         prefix_sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m    207\u001b[0m         dummy_na\u001b[39m=\u001b[39;49mdummy_na,\n\u001b[0;32m    208\u001b[0m         sparse\u001b[39m=\u001b[39;49msparse,\n\u001b[0;32m    209\u001b[0m         drop_first\u001b[39m=\u001b[39;49mdrop_first,\n\u001b[0;32m    210\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[0;32m    212\u001b[0m     with_dummies\u001b[39m.\u001b[39mappend(dummy)\n\u001b[0;32m    213\u001b[0m result \u001b[39m=\u001b[39m concat(with_dummies, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\natha\\OneDrive\\Documents\\WeLoveDataScience\\py-targeter\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:324\u001b[0m, in \u001b[0;36m_get_dummies_1d\u001b[1;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     eye_dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbool_\n\u001b[1;32m--> 324\u001b[0m dummy_mat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49meye(number_of_cols, dtype\u001b[39m=\u001b[39;49meye_dtype)\u001b[39m.\u001b[39mtake(codes, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mT\n\u001b[0;32m    326\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m dummy_na:\n\u001b[0;32m    327\u001b[0m     \u001b[39m# reset NaN GH4446\u001b[39;00m\n\u001b[0;32m    328\u001b[0m     dummy_mat[codes \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\natha\\OneDrive\\Documents\\WeLoveDataScience\\py-targeter\\.venv\\Lib\\site-packages\\numpy\\lib\\twodim_base.py:211\u001b[0m, in \u001b[0;36meye\u001b[1;34m(N, M, k, dtype, order, like)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39mif\u001b[39;00m M \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     M \u001b[39m=\u001b[39m N\n\u001b[1;32m--> 211\u001b[0m m \u001b[39m=\u001b[39m zeros((N, M), dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder)\n\u001b[0;32m    212\u001b[0m \u001b[39mif\u001b[39;00m k \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m M:\n\u001b[0;32m    213\u001b[0m     \u001b[39mreturn\u001b[39;00m m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 26.7 GiB for an array with shape (169452, 169452) and data type bool"
     ]
    }
   ],
   "source": [
    "one_hot_df = pd.get_dummies(df,drop_first=True)\n",
    "one_hot_df = one_hot_df.fillna(one_hot_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df_interactions = pd.get_dummies(df_interactions,drop_first=True)\n",
    "one_hot_df_interactions = one_hot_df_interactions.fillna(one_hot_df_interactions.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[df[target].notnull()]['O_523'].values\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(one_hot_df_interactions,Y, test_size=0.2, shuffle=True,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = PLSRegression(n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = mdl.fit(X1_train, Y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mdl.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(Y1_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SequentialFeatureSelector(estimator=mdl, direction='forward', n_features_to_select=\"auto\")\n",
    "selector = selector.fit(X1_train, Y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indices = selector.get_support()\n",
    "selected_feature_names = X1_train.columns[selected_indices]\n",
    "print(\"Caractéristiques sélectionnées :\", selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'O_523 ~ C_GroupeSelonCompo * C_LangueClient *  C_PaysClient * C_CommunauteClient' \n",
    "model = ols(formula=formula, data=df).fit()\n",
    "\n",
    "anova_table = sm.stats.anova_lm(model, typ=3)\n",
    "\n",
    "print(\"Tableau ANOVA :\")\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'O_523 ~ N_HC_21 * N_HC_22 * B_HC_12 * B_Filtre_Equipement_FeuOuvert * B_HC_6' \n",
    "model = ols(formula=formula, data=df).fit()\n",
    "\n",
    "anova_table = sm.stats.anova_lm(model, typ=3)\n",
    "\n",
    "print(\"Tableau ANOVA :\")\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_variables = anova_table1[anova_table1['PR(>F)'] < 0.1].index.tolist()\n",
    "\n",
    "print(\"Noms de variables significatives au seuil de 5% :\")\n",
    "print(significant_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interactions = df[self.selection].copy()\n",
    "df_interactions['B_HC_12*B_HC_6'] = df['B_HC_12'].apply(float) * df['B_HC_6'].apply(float)\n",
    "df_interactions['B_Filtre_Equipement_FeuOuvert*B_HC_6'] = df['B_Filtre_Equipement_FeuOuvert'].apply(float) * df['B_HC_6'].apply(float)\n",
    "df_interactions['B_Filtre_Equipement_FeuOuvert*N_HC_21'] = df['B_Filtre_Equipement_FeuOuvert'].apply(float) * df['N_HC_21'].apply(float)\n",
    "df_interactions['B_HC_6*N_HC_21'] = df['B_HC_6'].apply(float) * df['N_HC_21'].apply(float)\n",
    "print(df_interactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interactions['N_Maison_Cote_Maison_Moyenne_18M*N_nombre_nuit'] = df['N_Maison_Cote_Maison_Moyenne_18M'].apply(float) * df['N_nombre_nuit'].apply(float)\n",
    "df_interactions['Superficie*N_nombre_nuit'] = df['Superficie'].apply(float) * df['N_nombre_nuit'].apply(float)\n",
    "df_interactions['Superficie*N_nombre_nuit'] = df['Superficie'].apply(float) * df['N_nombre_nuit'].apply(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
